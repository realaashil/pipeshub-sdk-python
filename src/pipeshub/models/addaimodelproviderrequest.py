"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .modeltype import ModelType
from pipeshub.types import BaseModel, Nullable, OptionalNullable, UNSET, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class AddAIModelProviderRequestConfigurationTypedDict(TypedDict):
    r"""Provider-specific configuration"""

    model: NotRequired[str]
    r"""Model name/identifier"""
    api_key: NotRequired[str]
    r"""API key for the provider"""
    endpoint: NotRequired[str]
    r"""Custom endpoint URL (for Azure, self-hosted)"""
    organization_id: NotRequired[str]
    r"""Organization ID (OpenAI)"""
    deployment_name: NotRequired[str]
    r"""Deployment name (Azure OpenAI)"""
    aws_access_key_id: NotRequired[str]
    r"""AWS access key (Bedrock)"""
    aws_access_secret_key: NotRequired[str]
    r"""AWS secret key (Bedrock)"""
    region: NotRequired[str]
    r"""AWS region (Bedrock)"""


class AddAIModelProviderRequestConfiguration(BaseModel):
    r"""Provider-specific configuration"""

    model: Optional[str] = None
    r"""Model name/identifier"""

    api_key: Annotated[Optional[str], pydantic.Field(alias="apiKey")] = None
    r"""API key for the provider"""

    endpoint: Optional[str] = None
    r"""Custom endpoint URL (for Azure, self-hosted)"""

    organization_id: Annotated[
        Optional[str], pydantic.Field(alias="organizationId")
    ] = None
    r"""Organization ID (OpenAI)"""

    deployment_name: Annotated[
        Optional[str], pydantic.Field(alias="deploymentName")
    ] = None
    r"""Deployment name (Azure OpenAI)"""

    aws_access_key_id: Annotated[
        Optional[str], pydantic.Field(alias="awsAccessKeyId")
    ] = None
    r"""AWS access key (Bedrock)"""

    aws_access_secret_key: Annotated[
        Optional[str], pydantic.Field(alias="awsAccessSecretKey")
    ] = None
    r"""AWS secret key (Bedrock)"""

    region: Optional[str] = None
    r"""AWS region (Bedrock)"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "model",
                "apiKey",
                "endpoint",
                "organizationId",
                "deploymentName",
                "awsAccessKeyId",
                "awsAccessSecretKey",
                "region",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class AddAIModelProviderRequestTypedDict(TypedDict):
    r"""Request to add a new AI model provider"""

    model_type: ModelType
    r"""Type of AI model"""
    provider: str
    r"""Provider name (e.g., openai, anthropic, azure-openai, aws-bedrock)"""
    configuration: AddAIModelProviderRequestConfigurationTypedDict
    r"""Provider-specific configuration"""
    is_multimodal: NotRequired[bool]
    r"""Whether the model supports multimodal inputs"""
    is_reasoning: NotRequired[bool]
    r"""Whether this is a reasoning model"""
    is_default: NotRequired[bool]
    r"""Set as default model for this type"""
    context_length: NotRequired[Nullable[int]]
    r"""Maximum context length (tokens)"""


class AddAIModelProviderRequest(BaseModel):
    r"""Request to add a new AI model provider"""

    model_type: Annotated[ModelType, pydantic.Field(alias="modelType")]
    r"""Type of AI model"""

    provider: str
    r"""Provider name (e.g., openai, anthropic, azure-openai, aws-bedrock)"""

    configuration: AddAIModelProviderRequestConfiguration
    r"""Provider-specific configuration"""

    is_multimodal: Annotated[Optional[bool], pydantic.Field(alias="isMultimodal")] = (
        False
    )
    r"""Whether the model supports multimodal inputs"""

    is_reasoning: Annotated[Optional[bool], pydantic.Field(alias="isReasoning")] = False
    r"""Whether this is a reasoning model"""

    is_default: Annotated[Optional[bool], pydantic.Field(alias="isDefault")] = False
    r"""Set as default model for this type"""

    context_length: Annotated[
        OptionalNullable[int], pydantic.Field(alias="contextLength")
    ] = UNSET
    r"""Maximum context length (tokens)"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            ["isMultimodal", "isReasoning", "isDefault", "contextLength"]
        )
        nullable_fields = set(["contextLength"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            is_nullable_and_explicitly_set = (
                k in nullable_fields
                and (self.__pydantic_fields_set__.intersection({n}))  # pylint: disable=no-member
            )

            if val != UNSET_SENTINEL:
                if (
                    val is not None
                    or k not in optional_fields
                    or is_nullable_and_explicitly_set
                ):
                    m[k] = val

        return m


try:
    AddAIModelProviderRequestConfiguration.model_rebuild()
except NameError:
    pass
try:
    AddAIModelProviderRequest.model_rebuild()
except NameError:
    pass
