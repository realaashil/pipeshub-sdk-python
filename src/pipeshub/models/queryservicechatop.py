"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from pipeshub.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import List, Literal, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


QUERY_SERVICE_CHAT_OP_SERVERS = [
    # Query Service (Internal)
    "http://localhost:8000",
]


QueryServiceChatRole = Literal[
    "user_query",
    "bot_response",
]


class PreviousConversationTypedDict(TypedDict):
    role: NotRequired[QueryServiceChatRole]
    content: NotRequired[str]


class PreviousConversation(BaseModel):
    role: Optional[QueryServiceChatRole] = None

    content: Optional[str] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["role", "content"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class QueryServiceChatFiltersTypedDict(TypedDict):
    pass


class QueryServiceChatFilters(BaseModel):
    pass


RetrievalMode = Literal[
    "HYBRID",
    "VECTOR",
    "KEYWORD",
]


ChatMode = Literal[
    "quick",
    "analysis",
    "deep_research",
    "creative",
    "precise",
    "standard",
]


class QueryServiceChatRequestTypedDict(TypedDict):
    r"""Request payload"""

    query: str
    r"""User's question"""
    limit: NotRequired[int]
    previous_conversations: NotRequired[List[PreviousConversationTypedDict]]
    filters: NotRequired[QueryServiceChatFiltersTypedDict]
    retrieval_mode: NotRequired[RetrievalMode]
    quick_mode: NotRequired[bool]
    model_key: NotRequired[str]
    r"""UUID of the model configuration"""
    model_name: NotRequired[str]
    r"""Model name (e.g., gpt-4o-mini, claude-3-5-sonnet)"""
    chat_mode: NotRequired[ChatMode]


class QueryServiceChatRequest(BaseModel):
    r"""Request payload"""

    query: str
    r"""User's question"""

    limit: Optional[int] = 50

    previous_conversations: Annotated[
        Optional[List[PreviousConversation]],
        pydantic.Field(alias="previousConversations"),
    ] = None

    filters: Optional[QueryServiceChatFilters] = None

    retrieval_mode: Annotated[
        Optional[RetrievalMode], pydantic.Field(alias="retrievalMode")
    ] = "HYBRID"

    quick_mode: Annotated[Optional[bool], pydantic.Field(alias="quickMode")] = False

    model_key: Annotated[Optional[str], pydantic.Field(alias="modelKey")] = None
    r"""UUID of the model configuration"""

    model_name: Annotated[Optional[str], pydantic.Field(alias="modelName")] = None
    r"""Model name (e.g., gpt-4o-mini, claude-3-5-sonnet)"""

    chat_mode: Annotated[Optional[ChatMode], pydantic.Field(alias="chatMode")] = (
        "standard"
    )

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "limit",
                "previousConversations",
                "filters",
                "retrievalMode",
                "quickMode",
                "modelKey",
                "modelName",
                "chatMode",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


try:
    QueryServiceChatRequest.model_rebuild()
except NameError:
    pass
