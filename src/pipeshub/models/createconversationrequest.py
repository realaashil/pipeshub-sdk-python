"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .filters import Filters, FiltersTypedDict
from pipeshub.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class CreateConversationRequestTypedDict(TypedDict):
    r"""Request body for creating a new AI conversation.<br><br>
    <b>Query Processing:</b><br>
    The query is processed through PipesHub's AI pipeline which:
    <ul>
    <li>Performs semantic search across indexed knowledge bases</li>
    <li>Retrieves relevant context from matching documents</li>
    <li>Generates a response with citations to source materials</li>
    <li>Suggests follow-up questions based on the conversation</li>
    </ul>

    """

    query: str
    r"""The user's question or prompt to start the conversation.
    Supports natural language queries of any complexity.

    """
    record_ids: NotRequired[List[str]]
    r"""Limit the AI's knowledge scope to specific records/documents.
    When provided, only these records will be searched for context.

    """
    departments: NotRequired[List[str]]
    r"""Filter by department IDs to scope the search"""
    filters: NotRequired[FiltersTypedDict]
    model_key: NotRequired[str]
    r"""Identifier for the AI model configuration to use.
    Available models depend on organization settings.

    """
    model_name: NotRequired[str]
    r"""Display name of the AI model"""
    chat_mode: NotRequired[str]
    r"""Chat mode affecting response behavior.
    Different modes optimize for different use cases.

    """


class CreateConversationRequest(BaseModel):
    r"""Request body for creating a new AI conversation.<br><br>
    <b>Query Processing:</b><br>
    The query is processed through PipesHub's AI pipeline which:
    <ul>
    <li>Performs semantic search across indexed knowledge bases</li>
    <li>Retrieves relevant context from matching documents</li>
    <li>Generates a response with citations to source materials</li>
    <li>Suggests follow-up questions based on the conversation</li>
    </ul>

    """

    query: str
    r"""The user's question or prompt to start the conversation.
    Supports natural language queries of any complexity.

    """

    record_ids: Annotated[Optional[List[str]], pydantic.Field(alias="recordIds")] = None
    r"""Limit the AI's knowledge scope to specific records/documents.
    When provided, only these records will be searched for context.

    """

    departments: Optional[List[str]] = None
    r"""Filter by department IDs to scope the search"""

    filters: Optional[Filters] = None

    model_key: Annotated[Optional[str], pydantic.Field(alias="modelKey")] = None
    r"""Identifier for the AI model configuration to use.
    Available models depend on organization settings.

    """

    model_name: Annotated[Optional[str], pydantic.Field(alias="modelName")] = None
    r"""Display name of the AI model"""

    chat_mode: Annotated[Optional[str], pydantic.Field(alias="chatMode")] = None
    r"""Chat mode affecting response behavior.
    Different modes optimize for different use cases.

    """

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            ["recordIds", "departments", "filters", "modelKey", "modelName", "chatMode"]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


try:
    CreateConversationRequest.model_rebuild()
except NameError:
    pass
