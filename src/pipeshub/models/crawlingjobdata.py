"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .scheduleconfig import ScheduleConfig, ScheduleConfigTypedDict
from datetime import datetime
from pipeshub.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import Any, Dict, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class CrawlingJobDataTypedDict(TypedDict):
    r"""Data payload stored with each crawling job in the queue"""

    connector: str
    r"""Connector type identifier (e.g., \"drive\", \"onedrive\", \"slack\")"""
    connector_id: str
    r"""Unique identifier of the connector instance"""
    schedule_config: ScheduleConfigTypedDict
    r"""Schedule configuration for crawling jobs. The structure varies based on <code>scheduleType</code>.<br><br>
    <b>Schedule Type Configurations:</b><br>
    <ul>
    <li><b>hourly:</b> <code>minute</code>, <code>interval</code> (optional)</li>
    <li><b>daily:</b> <code>hour</code>, <code>minute</code></li>
    <li><b>weekly:</b> <code>daysOfWeek</code>, <code>hour</code>, <code>minute</code></li>
    <li><b>monthly:</b> <code>dayOfMonth</code>, <code>hour</code>, <code>minute</code></li>
    <li><b>custom:</b> <code>cronExpression</code>, <code>description</code> (optional)</li>
    <li><b>once:</b> <code>scheduledTime</code></li>
    </ul>

    """
    org_id: str
    r"""Organization ID that owns this crawling job"""
    user_id: str
    r"""User ID who created/scheduled this job"""
    timestamp: datetime
    r"""When the job was created/scheduled"""
    metadata: NotRequired[Dict[str, Any]]
    r"""Optional additional metadata for the job"""


class CrawlingJobData(BaseModel):
    r"""Data payload stored with each crawling job in the queue"""

    connector: str
    r"""Connector type identifier (e.g., \"drive\", \"onedrive\", \"slack\")"""

    connector_id: Annotated[str, pydantic.Field(alias="connectorId")]
    r"""Unique identifier of the connector instance"""

    schedule_config: Annotated[ScheduleConfig, pydantic.Field(alias="scheduleConfig")]
    r"""Schedule configuration for crawling jobs. The structure varies based on <code>scheduleType</code>.<br><br>
    <b>Schedule Type Configurations:</b><br>
    <ul>
    <li><b>hourly:</b> <code>minute</code>, <code>interval</code> (optional)</li>
    <li><b>daily:</b> <code>hour</code>, <code>minute</code></li>
    <li><b>weekly:</b> <code>daysOfWeek</code>, <code>hour</code>, <code>minute</code></li>
    <li><b>monthly:</b> <code>dayOfMonth</code>, <code>hour</code>, <code>minute</code></li>
    <li><b>custom:</b> <code>cronExpression</code>, <code>description</code> (optional)</li>
    <li><b>once:</b> <code>scheduledTime</code></li>
    </ul>

    """

    org_id: Annotated[str, pydantic.Field(alias="orgId")]
    r"""Organization ID that owns this crawling job"""

    user_id: Annotated[str, pydantic.Field(alias="userId")]
    r"""User ID who created/scheduled this job"""

    timestamp: datetime
    r"""When the job was created/scheduled"""

    metadata: Optional[Dict[str, Any]] = None
    r"""Optional additional metadata for the job"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["metadata"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


try:
    CrawlingJobData.model_rebuild()
except NameError:
    pass
