"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .filters import Filters, FiltersTypedDict
from pipeshub.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class SemanticSearchRequestTypedDict(TypedDict):
    r"""Request body for performing semantic search across the enterprise knowledge base.<br><br>
    <b>How Semantic Search Works:</b><br>
    <ol>
    <li>Query is converted to vector embeddings</li>
    <li>Similar content is found using vector similarity</li>
    <li>Results are ranked by relevance score</li>
    <li>Matching chunks with metadata are returned</li>
    </ol>
    <b>Filtering:</b><br>
    Use filters to narrow search scope to specific apps or knowledge bases.

    """

    query: str
    r"""Natural language search query. The system understands
    semantic meaning, not just keywords.

    """
    filters: NotRequired[FiltersTypedDict]
    limit: NotRequired[int]
    r"""Maximum number of results to return"""
    model_key: NotRequired[str]
    r"""AI model to use for embeddings"""
    model_name: NotRequired[str]
    r"""Display name of the model"""
    chat_mode: NotRequired[str]
    r"""Processing mode configuration"""


class SemanticSearchRequest(BaseModel):
    r"""Request body for performing semantic search across the enterprise knowledge base.<br><br>
    <b>How Semantic Search Works:</b><br>
    <ol>
    <li>Query is converted to vector embeddings</li>
    <li>Similar content is found using vector similarity</li>
    <li>Results are ranked by relevance score</li>
    <li>Matching chunks with metadata are returned</li>
    </ol>
    <b>Filtering:</b><br>
    Use filters to narrow search scope to specific apps or knowledge bases.

    """

    query: str
    r"""Natural language search query. The system understands
    semantic meaning, not just keywords.

    """

    filters: Optional[Filters] = None

    limit: Optional[int] = 10
    r"""Maximum number of results to return"""

    model_key: Annotated[Optional[str], pydantic.Field(alias="modelKey")] = None
    r"""AI model to use for embeddings"""

    model_name: Annotated[Optional[str], pydantic.Field(alias="modelName")] = None
    r"""Display name of the model"""

    chat_mode: Annotated[Optional[str], pydantic.Field(alias="chatMode")] = None
    r"""Processing mode configuration"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["filters", "limit", "modelKey", "modelName", "chatMode"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


try:
    SemanticSearchRequest.model_rebuild()
except NameError:
    pass
