"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from .basesdk import BaseSDK
from pipeshub import errors, models, utils
from pipeshub._hooks import HookContext
from pipeshub.types import OptionalNullable, UNSET
from pipeshub.utils import get_security_from_env
from pipeshub.utils.unmarshal_json_response import unmarshal_json_response
from typing import List, Mapping, Optional, Union


class AiModelsConfiguration(BaseSDK):
    def create(
        self,
        *,
        ocr: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        embedding: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        slm: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        llm: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        reasoning: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        multi_modal: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ):
        r"""Bulk create AI models configuration

        Configure multiple AI model providers at once. Performs health checks on each model before saving. Use this for initial setup - for individual model management, use /ai-models/providers endpoints.

        :param ocr:
        :param embedding:
        :param slm:
        :param llm:
        :param reasoning:
        :param multi_modal:
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.AIModelsConfigInput(
            ocr=utils.get_pydantic_model(
                ocr, Optional[List[models.AIModelProviderConfigInput]]
            ),
            embedding=utils.get_pydantic_model(
                embedding, Optional[List[models.AIModelProviderConfigInput]]
            ),
            slm=utils.get_pydantic_model(
                slm, Optional[List[models.AIModelProviderConfigInput]]
            ),
            llm=utils.get_pydantic_model(
                llm, Optional[List[models.AIModelProviderConfigInput]]
            ),
            reasoning=utils.get_pydantic_model(
                reasoning, Optional[List[models.AIModelProviderConfigInput]]
            ),
            multi_modal=utils.get_pydantic_model(
                multi_modal, Optional[List[models.AIModelProviderConfigInput]]
            ),
        )

        req = self._build_request(
            method="POST",
            path="/configurationManager/aiModelsConfig",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="*/*",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.AIModelsConfigInput
            ),
            allow_empty_value=None,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="createAIModelsConfig",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["400", "401", "403", "4XX", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "*"):
            return
        if utils.match_response(http_res, ["400", "401", "403", "4XX"], "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise errors.PipeshubDefaultError(
                "API error occurred", http_res, http_res_text
            )
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise errors.PipeshubDefaultError(
                "API error occurred", http_res, http_res_text
            )

        raise errors.PipeshubDefaultError("Unexpected response received", http_res)

    async def create_async(
        self,
        *,
        ocr: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        embedding: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        slm: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        llm: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        reasoning: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        multi_modal: Optional[
            Union[
                List[models.AIModelProviderConfigInput],
                List[models.AIModelProviderConfigInputTypedDict],
            ]
        ] = None,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ):
        r"""Bulk create AI models configuration

        Configure multiple AI model providers at once. Performs health checks on each model before saving. Use this for initial setup - for individual model management, use /ai-models/providers endpoints.

        :param ocr:
        :param embedding:
        :param slm:
        :param llm:
        :param reasoning:
        :param multi_modal:
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.AIModelsConfigInput(
            ocr=utils.get_pydantic_model(
                ocr, Optional[List[models.AIModelProviderConfigInput]]
            ),
            embedding=utils.get_pydantic_model(
                embedding, Optional[List[models.AIModelProviderConfigInput]]
            ),
            slm=utils.get_pydantic_model(
                slm, Optional[List[models.AIModelProviderConfigInput]]
            ),
            llm=utils.get_pydantic_model(
                llm, Optional[List[models.AIModelProviderConfigInput]]
            ),
            reasoning=utils.get_pydantic_model(
                reasoning, Optional[List[models.AIModelProviderConfigInput]]
            ),
            multi_modal=utils.get_pydantic_model(
                multi_modal, Optional[List[models.AIModelProviderConfigInput]]
            ),
        )

        req = self._build_request_async(
            method="POST",
            path="/configurationManager/aiModelsConfig",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="*/*",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.AIModelsConfigInput
            ),
            allow_empty_value=None,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="createAIModelsConfig",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["400", "401", "403", "4XX", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "*"):
            return
        if utils.match_response(http_res, ["400", "401", "403", "4XX"], "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise errors.PipeshubDefaultError(
                "API error occurred", http_res, http_res_text
            )
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise errors.PipeshubDefaultError(
                "API error occurred", http_res, http_res_text
            )

        raise errors.PipeshubDefaultError("Unexpected response received", http_res)

    def get(
        self,
        *,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.AIModelsConfig:
        r"""Get all AI models configuration

        Retrieve all configured AI model providers grouped by type.

        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)
        req = self._build_request(
            method="GET",
            path="/configurationManager/aiModelsConfig",
            base_url=base_url,
            url_variables=url_variables,
            request=None,
            request_body_required=False,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            allow_empty_value=None,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="getAIModelsConfig",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["401", "4XX", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(models.AIModelsConfig, http_res)
        if utils.match_response(http_res, ["401", "4XX"], "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise errors.PipeshubDefaultError(
                "API error occurred", http_res, http_res_text
            )
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise errors.PipeshubDefaultError(
                "API error occurred", http_res, http_res_text
            )

        raise errors.PipeshubDefaultError("Unexpected response received", http_res)

    async def get_async(
        self,
        *,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.AIModelsConfig:
        r"""Get all AI models configuration

        Retrieve all configured AI model providers grouped by type.

        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)
        req = self._build_request_async(
            method="GET",
            path="/configurationManager/aiModelsConfig",
            base_url=base_url,
            url_variables=url_variables,
            request=None,
            request_body_required=False,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            allow_empty_value=None,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="getAIModelsConfig",
                oauth2_scopes=None,
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["401", "4XX", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(models.AIModelsConfig, http_res)
        if utils.match_response(http_res, ["401", "4XX"], "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise errors.PipeshubDefaultError(
                "API error occurred", http_res, http_res_text
            )
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise errors.PipeshubDefaultError(
                "API error occurred", http_res, http_res_text
            )

        raise errors.PipeshubDefaultError("Unexpected response received", http_res)
